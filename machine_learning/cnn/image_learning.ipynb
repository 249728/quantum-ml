{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Total number of samples : 203\n",
      "Training samples : 162\n",
      "Test samples : 41\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x122b2b320>, '_save_summary_steps': 100, '_evaluation_master': '', '_is_chief': True, '_task_type': None, '_task_id': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_model_dir': None, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_master': '', '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_environment': 'local'}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpcc3fvb65\n",
      "WARNING:tensorflow:From <ipython-input-185-960f12675efa>:103: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-185-960f12675efa>:103: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-185-960f12675efa>:103: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpcc3fvb65/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.96072, step = 1\n",
      "INFO:tensorflow:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-960f12675efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     monitors=[logging_hook])\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m metrics = {\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    283\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0mSKCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, steps, max_steps, monitors)\u001b[0m\n\u001b[1;32m   1315\u001b[0m                         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m                         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m                         monitors=all_monitors)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    283\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    482\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    818\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learn the states of a double dot\n",
    "%reset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# application logic will be added here\n",
    "def cnn_model_fn(features,labels,mode):\n",
    "    '''Model function for CNN'''\n",
    "    #input layer\n",
    "    input_layer = tf.cast(tf.reshape(features,[-1,100,100,1]),tf.float32)\n",
    "    \n",
    "    # Concolutional layer1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=4,\n",
    "        kernel_size=[10,10],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling layer1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[5,5],strides=5)\n",
    "\n",
    "    # Dense layer\n",
    "    pool2_flat = tf.contrib.layers.flatten(pool1)\n",
    "    dense1 = tf.layers.dense(inputs=pool2_flat,units=256,activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(inputs=dense1,rate=0.5,training=mode == learn.ModeKeys.TRAIN)\n",
    "    \n",
    "    dense2 = tf.layers.dense(inputs=dropout1,units=128,activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(inputs=dense2,rate=0.5,training=mode == learn.ModeKeys.TRAIN)\n",
    "\n",
    "    # encode layer\n",
    "    encode = tf.layers.dense(inputs=dropout2,units=4)\n",
    "    \n",
    "    # dense output layer\n",
    "    out_layer = tf.layers.dense(inputs=encode,units=10000)\n",
    "\n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "    # Calculate loss( for both TRAIN AND EVAL modes)\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=out_layer)\n",
    "\n",
    "    # Configure the training op (for TRAIN mode)\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=0.1,\n",
    "            optimizer=\"Adam\")\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions= {\n",
    "        \"states\" : tf.rint(out_layer),\n",
    "    }\n",
    "\n",
    "    # Returna  ModelFnOps object\n",
    "    return model_fn_lib.ModelFnOps(mode=mode,predictions=predictions,loss=loss, train_op=train_op)\n",
    "    \n",
    "\n",
    "# get the data\n",
    "data_files = glob.glob(os.path.expanduser('~/quantum-ml/dataproc_cnn/*100*.npy'))\n",
    "inp = []\n",
    "oup = []\n",
    "for file in data_files:\n",
    "    data_dict = np.load(file).item()\n",
    "    inp += [data_dict['current_map']]\n",
    "    oup += [data_dict['state_map'].flatten()]\n",
    "\n",
    "inp = np.array(inp)\n",
    "oup = np.array(oup)\n",
    "n_samples = inp.shape[0]\n",
    "train_sample_ratio = 0.8\n",
    "n_train = int(train_sample_ratio * n_samples)\n",
    "print(\"Total number of samples :\",n_samples)\n",
    "print(\"Training samples :\",n_train)\n",
    "print(\"Test samples :\",n_samples - n_train)\n",
    "train_data = inp[:n_train]\n",
    "train_labels = oup[:n_train]\n",
    "\n",
    "test_data = inp[n_train:]\n",
    "test_labels = oup[n_train:]\n",
    "\n",
    "# create the estimator\n",
    "dd_classifier = learn.Estimator(model_fn=cnn_model_fn)\n",
    "\n",
    "# set up logging for predictions\n",
    "tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=500)\n",
    "\n",
    "dd_classifier.fit(\n",
    "    x=train_data,\n",
    "    y=train_labels,\n",
    "    batch_size=10,\n",
    "    steps=10000,\n",
    "    monitors=[logging_hook])\n",
    "    \n",
    "metrics = {\n",
    "    \"accuracy\" : learn.MetricSpec(metric_fn=tf.metrics.accuracy, prediction_key=\"states\"),\n",
    "}\n",
    "\n",
    "eval_results=dd_classifier.evaluate(x=test_data,y=test_labels,metrics=metrics)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for i,p in enumerate(predictions):\n",
    "    res_list += [p['states'].reshape((100,100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x147d6c2e8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqP8HkYC4lTAMCXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1213d2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolor(res_list[3])\n",
    "plt.subplot(2,1,2)\n",
    "plt.pcolor(test_labels[3].reshape((100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-177-bffba77c8151>:1: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpf8zn5zew/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "predictions = dd_classifier.predict(x=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseEstimator._predict_generator at 0x12baec938>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "plt.rcParams['animation.ffmpeg_path'] ='/usr/local/bin/ffmpeg'\n",
    "%matplotlib \n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "XX,YY = np.meshgrid(np.linspace(50e-3,500e-3,100),np.linspace(50e-3,500e-3,100))\n",
    "\n",
    "def fixed_aspect_ratio(ax,ratio):\n",
    "    '''\n",
    "    Set a fixed aspect ratio on matplotlib plots \n",
    "    regardless of axis units\n",
    "    '''\n",
    "    xvals,yvals = ax.axes.get_xlim(),ax.axes.get_ylim()\n",
    "\n",
    "    xrange = xvals[1]-xvals[0]\n",
    "    yrange = yvals[1]-yvals[0]\n",
    "    ax.set_aspect(ratio*(xrange/yrange), adjustable='box')\n",
    "    \n",
    "\n",
    "def animate(i):\n",
    "    my_cmap = mpl.colors.ListedColormap([[0., .4, 1.], [0., .8, 1.],\n",
    "                                  [1., .8, 0.], [1., .4, 0.]])\n",
    "    \n",
    "    line = ax[0].pcolor(XX,YY,predictions_list[i][0],vmin=-1,vmax=2,cmap = my_cmap,alpha=0.9)\n",
    "    fixed_aspect_ratio(ax[0],1.0)\n",
    "    ax[0].set_title(r'Predicted $n_{iter} = $' + str(i*500))\n",
    "    \n",
    "    return line,\n",
    "\n",
    "\n",
    "# Init only required for blitting to give a clean slate.\n",
    "def init():\n",
    "    \n",
    "    my_cmap = mpl.colors.ListedColormap([[0., .4, 1.], [0., .8, 1.],\n",
    "                                  [1., .8, 0.], [1., .4, 0.]])\n",
    "    \n",
    "    line = ax[0].pcolor(XX,YY,predictions_list[0][0],vmin=-1,vmax=2,cmap = my_cmap,alpha=0.9)\n",
    "    fixed_aspect_ratio(ax[0],1.0)\n",
    "    cbar_0 = plt.colorbar(line,ax=ax[0],cmap=my_cmap,ticks=[-1,0,1,2],fraction=0.046, pad=0.04)\n",
    "    cbar_0.set_ticklabels([\"SC\",\"QPC\",\"1Dot\",\"2Dot\"])\n",
    "    cbar_0.set_ticks([-0.5,0.5,1.5,2.5])\n",
    "    ax[0].set_xlabel(r'$V_{d1} (V)$',fontsize=12)\n",
    "    ax[0].set_ylabel(r'$V_{d2} (V)$',fontsize=12)\n",
    "    ax[0].set_title(r'Expected $n_{iter} = $' + str(0))\n",
    "    ax[0].set_title('Predicted')\n",
    "    \n",
    "    \n",
    "    line2 = ax[1].pcolor(XX,YY,test_labels[0].reshape((100,100)),vmin=-1,vmax=2,cmap = my_cmap,alpha=0.9)\n",
    "    fixed_aspect_ratio(ax[1],1.0)\n",
    "    cbar_1 = plt.colorbar(line2,ax=ax[1],cmap=my_cmap,ticks=[-1,0,1,2],fraction=0.046, pad=0.04)\n",
    "    cbar_1.set_ticklabels([\"SC\",\"QPC\",\"1Dot\",\"2Dot\"])\n",
    "    cbar_1.set_ticks([-0.5,0.5,1.5,2.5])\n",
    "    ax[1].set_xlabel(r'$V_{d1} (V)$',fontsize=12)\n",
    "    ax[1].set_ylabel(r'$V_{d2} (V)$',fontsize=12)\n",
    "    ax[1].set_title('Expected')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    return line,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, np.arange(100) , init_func=init,\n",
    "                              interval=500, blit=True)\n",
    "\n",
    "mywriter = animation.FFMpegWriter()\n",
    "ani.save('dd_learning.mp4',writer=mywriter)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0., -0., ...,  0.,  0.,  0.],\n",
       "       [-0.,  0., -0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ..., -0., -0., -0.],\n",
       "       [ 0.,  0.,  0., ..., -0., -0., -0.],\n",
       "       [ 0.,  0.,  0., ..., -0., -0., -0.]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list[0][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
