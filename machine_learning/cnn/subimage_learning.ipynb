{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook will be used to work on the subimage problem\n",
    "# The idea is to generate 20x20 subimages of the orginal double dots maps. \n",
    "# Each subimage will have a single label : one of single dot, double dot, QPC or ShortCircuit\n",
    "# The label will be decided by the majority label in the subimage from the state classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This input box will be used to generate sub image data and the corresponding labels.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# this function finds the majority state in the subimage\n",
    "def find_state(x,y,sub_size,dat):\n",
    "    charge_map = list(dat.item()['state_map'][(x - int(sub_size/2)) :\n",
    "                                     (x + int(sub_size/2)),(y - int(sub_size/2)):(y+int(sub_size/2))].flatten())\n",
    "    max_state = max(map(lambda val: (charge_map.count(val), val), set(charge_map)))[1]\n",
    "    return max_state\n",
    "\n",
    "# this function finds the prob. vector of the states corresponding to the subimage\n",
    "def find_prob(x,y,sub_size,dat):\n",
    "    prob = np.histogram(dat.item()['state_map']\\\n",
    "                    [(x - int(sub_size/2)) :(x + int(sub_size/2)),(y - int(sub_size/2)):(y+int(sub_size/2))]\\\n",
    "                    .flatten(),[-1,0,1,2,3])[0]\n",
    "    prob = prob/np.sum(prob)  \n",
    "\n",
    "data_folder_path = \"/Users/sandesh/dataproc/\"\n",
    "data_output_path = \"/Users/sandesh/data_subimage/\"\n",
    "files = glob.glob(data_folder_path + \"*.npy\")\n",
    "\n",
    "for file in files:\n",
    "    dat = np.load(file)\n",
    "    sub_size = 30\n",
    "    n_sub_images = 10\n",
    "    for i in range(n_sub_images):\n",
    "        x = np.random.randint(int(sub_size/2),100-int(sub_size/2))\n",
    "        y = np.random.randint(int(sub_size/2),100-int(sub_size/2))\n",
    "\n",
    "        prob_state = find_prob(x,y,sub_size,dat)\n",
    "        out = {}\n",
    "        out['current_map'] = dat.item()['current_map'][(x - int(sub_size/2)) :\n",
    "                                             (x + int(sub_size/2)),(y - int(sub_size/2)):(y+int(sub_size/2))]\n",
    "        out['label'] = prob_state\n",
    "\n",
    "        np.save(os.path.join(data_output_path,os.path.basename(file)[:-3] + \"_30_subimage_\" + str(i)),out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.98888889  0.01111111]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x11a497a90>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nItwBICHCHQASItwBIKH/BW8M3VY46CQJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10895a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder_path = \"/Users/sandesh/dataproc/\"\n",
    "files = glob.glob(data_folder_path + \"*.npy\")\n",
    "\n",
    "dat = np.load(files[1200])\n",
    "x = np.random.randint(int(sub_size/2),100-int(sub_size/2))\n",
    "y = np.random.randint(int(sub_size/2),100-int(sub_size/2))\n",
    "prob = np.histogram(dat.item()['state_map']\\\n",
    "                    [(x - int(sub_size/2)) :(x + int(sub_size/2)),(y - int(sub_size/2)):(y+int(sub_size/2))]\\\n",
    "                    .flatten(),[-1,0,1,2,3])[0]\n",
    "prob = prob/np.sum(prob)\n",
    "print(prob)\n",
    "plt.pcolor(dat.item()['current_map']\\\n",
    "                    [(x - int(sub_size/2)) :(x + int(sub_size/2)),(y - int(sub_size/2)):(y+int(sub_size/2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131508dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing of the generated subimage data\n",
    "data_folder_path = \"/Users/sandesh/data_subimage/\"\n",
    "files = glob.glob(data_folder_path + \"*.npy\")\n",
    "i = np.random.randint(len(files))\n",
    "load_dat = np.load(files[i])\n",
    "\n",
    "plt.pcolor(load_dat.item()['current_map'])\n",
    "print(load_dat.item()['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x130fb1fd0>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIFIEAABEigAAgEgRAAAQKQIAACL1/+vVqjSizB66AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130656710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing of the experimental data loading\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "\n",
    "data_folder_path = \"/Users/sandesh/exp_data/\"\n",
    "files = glob.glob(data_folder_path + \"*.dat\")\n",
    "\n",
    "# Data format is V_LGD I_DC(nA) V_LGS I_AC(nA) t(sec)\n",
    "# The format of the loaded array is [num_points,5]\n",
    "dat = np.loadtxt(files[2])\n",
    "sub_size = 100\n",
    "grid_x = np.linspace(-1.4,-1.3,sub_size)\n",
    "grid_y = np.linspace(-1.7,-1.6,sub_size)\n",
    "xx,yy = np.meshgrid(grid_x,grid_y)\n",
    "interpolated_data = scipy.interpolate.griddata((dat[:,0],dat[:,2]),dat[:,1],(xx, yy), method='nearest')\n",
    "\n",
    "plt.pcolor(interpolated_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples : 10000\n",
      "Training samples : 9000\n",
      "Test samples : 1000\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_model_dir': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_environment': 'local', '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11bdd34a8>, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_task_type': None, '_master': '', '_evaluation_master': ''}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 1.78683\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:global_step/sec: 32.5285\n",
      "INFO:tensorflow:step = 101, loss = 1.8072 (3.074 sec)\n",
      "INFO:tensorflow: (3.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.111\n",
      "INFO:tensorflow:step = 201, loss = 1.51255 (3.213 sec)\n",
      "INFO:tensorflow: (3.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5395\n",
      "INFO:tensorflow:step = 301, loss = 1.2025 (2.982 sec)\n",
      "INFO:tensorflow: (2.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7968\n",
      "INFO:tensorflow:step = 401, loss = 0.92087 (2.873 sec)\n",
      "INFO:tensorflow: (2.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4582\n",
      "INFO:tensorflow:step = 501, loss = 0.689669 (2.989 sec)\n",
      "INFO:tensorflow: (2.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0796\n",
      "INFO:tensorflow:step = 601, loss = 0.514239 (2.850 sec)\n",
      "INFO:tensorflow: (2.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1099\n",
      "INFO:tensorflow:step = 701, loss = 0.390033 (2.769 sec)\n",
      "INFO:tensorflow: (2.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3488\n",
      "INFO:tensorflow:step = 801, loss = 0.307542 (2.751 sec)\n",
      "INFO:tensorflow: (2.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3483\n",
      "INFO:tensorflow:step = 901, loss = 0.256507 (2.751 sec)\n",
      "INFO:tensorflow: (2.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.226323.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:53:53\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-1000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:53:54\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.74, global_step = 1000, loss = 0.226096\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.74000001, 'global_step': 1000, 'loss': 0.2260962}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:53:55\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-1000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:53:57\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.606, global_step = 1000, loss = 0.34695\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 1000, 'loss': 0.34695041}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 1001, loss = 0.299981\n",
      "INFO:tensorflow:global_step/sec: 35.1795\n",
      "INFO:tensorflow:step = 1101, loss = 0.275049 (2.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5358\n",
      "INFO:tensorflow:step = 1201, loss = 0.261631 (3.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7077\n",
      "INFO:tensorflow:step = 1301, loss = 0.255159 (3.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1091\n",
      "INFO:tensorflow:step = 1401, loss = 0.25214 (2.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4768\n",
      "INFO:tensorflow:step = 1501, loss = 0.250822 (2.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2707\n",
      "INFO:tensorflow:step = 1601, loss = 0.251871 (3.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3586\n",
      "INFO:tensorflow:step = 1701, loss = 0.250693 (2.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7265\n",
      "INFO:tensorflow:step = 1801, loss = 0.250221 (2.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3446\n",
      "INFO:tensorflow:step = 1901, loss = 0.250065 (2.678 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.250019.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:54:33\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:54:34\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.66, global_step = 2000, loss = 0.250018\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.66000003, 'global_step': 2000, 'loss': 0.25001848}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:54:35\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:54:35\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.606, global_step = 2000, loss = 0.276814\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 2000, 'loss': 0.27681428}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 2001, loss = 0.200986\n",
      "INFO:tensorflow:global_step/sec: 28.5554\n",
      "INFO:tensorflow:step = 2101, loss = 0.191466 (3.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5067\n",
      "INFO:tensorflow:step = 2201, loss = 0.18849 (2.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4103\n",
      "INFO:tensorflow:step = 2301, loss = 0.187705 (2.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4519\n",
      "INFO:tensorflow:step = 2401, loss = 0.187733 (2.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2995\n",
      "INFO:tensorflow:step = 2501, loss = 0.187623 (2.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.428\n",
      "INFO:tensorflow:step = 2601, loss = 0.187604 (2.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5261\n",
      "INFO:tensorflow:step = 2701, loss = 0.1876 (2.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3994\n",
      "INFO:tensorflow:step = 2801, loss = 0.1876 (2.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7839\n",
      "INFO:tensorflow:step = 2901, loss = 0.1876 (2.795 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1876.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:55:12\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-3000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:55:13\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.58, global_step = 3000, loss = 0.31561\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.57999998, 'global_step': 3000, 'loss': 0.31561002}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:55:14\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-3000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:55:15\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.606, global_step = 3000, loss = 0.301848\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 3000, 'loss': 0.30184838}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 3001, loss = 0.198804\n",
      "INFO:tensorflow:global_step/sec: 37.136\n",
      "INFO:tensorflow:step = 3101, loss = 0.193079 (2.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0694\n",
      "INFO:tensorflow:step = 3201, loss = 0.192447 (2.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4462\n",
      "INFO:tensorflow:step = 3301, loss = 0.192403 (2.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4301\n",
      "INFO:tensorflow:step = 3401, loss = 0.1924 (2.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.566\n",
      "INFO:tensorflow:step = 3501, loss = 0.1924 (2.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5446\n",
      "INFO:tensorflow:step = 3601, loss = 0.1924 (2.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3597\n",
      "INFO:tensorflow:step = 3701, loss = 0.1924 (2.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6998\n",
      "INFO:tensorflow:step = 3801, loss = 0.1924 (2.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.529\n",
      "INFO:tensorflow:step = 3901, loss = 0.1924 (2.737 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1924.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:55:50\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-4000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:55:51\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.7, global_step = 4000, loss = 0.2324\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.69999999, 'global_step': 4000, 'loss': 0.23240001}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:55:52\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-4000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:55:53\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.606, global_step = 4000, loss = 0.28168\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 4000, 'loss': 0.28167972}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 4001, loss = 0.2212\n",
      "INFO:tensorflow:global_step/sec: 36.8413\n",
      "INFO:tensorflow:step = 4101, loss = 0.217657 (2.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7646\n",
      "INFO:tensorflow:step = 4201, loss = 0.2176 (2.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.744\n",
      "INFO:tensorflow:step = 4301, loss = 0.2176 (2.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8013\n",
      "INFO:tensorflow:step = 4401, loss = 0.2176 (2.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0989\n",
      "INFO:tensorflow:step = 4501, loss = 0.2176 (2.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7842\n",
      "INFO:tensorflow:step = 4601, loss = 0.2176 (2.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7986\n",
      "INFO:tensorflow:step = 4701, loss = 0.2176 (2.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6105\n",
      "INFO:tensorflow:step = 4801, loss = 0.2176 (2.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2333\n",
      "INFO:tensorflow:step = 4901, loss = 0.2176 (2.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2176.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:56:27\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:56:28\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.74, global_step = 5000, loss = 0.2216\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.74000001, 'global_step': 5000, 'loss': 0.22159994}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:56:29\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:56:29\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.606, global_step = 5000, loss = 0.27496\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 5000, 'loss': 0.27496046}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 5001, loss = 0.2504\n",
      "INFO:tensorflow:global_step/sec: 36.6455\n",
      "INFO:tensorflow:step = 5101, loss = 0.25 (2.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6068\n",
      "INFO:tensorflow:step = 5201, loss = 0.25 (2.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7799\n",
      "INFO:tensorflow:step = 5301, loss = 0.25 (2.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5897\n",
      "INFO:tensorflow:step = 5401, loss = 0.25 (3.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.033\n",
      "INFO:tensorflow:step = 5501, loss = 0.25 (2.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2521\n",
      "INFO:tensorflow:step = 5601, loss = 0.25 (2.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0584\n",
      "INFO:tensorflow:step = 5701, loss = 0.25 (2.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9098\n",
      "INFO:tensorflow:step = 5801, loss = 0.25 (2.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8116\n",
      "INFO:tensorflow:step = 5901, loss = 0.25 (2.717 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.25.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:57:05\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-6000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:57:05\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.66, global_step = 6000, loss = 0.274\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.66000003, 'global_step': 6000, 'loss': 0.27399999}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:57:06\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-6000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:57:07\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.606, global_step = 6000, loss = 0.2764\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 6000, 'loss': 0.27639994}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 6001, loss = 0.298\n",
      "INFO:tensorflow:global_step/sec: 36.7206\n",
      "INFO:tensorflow:step = 6101, loss = 0.2976 (2.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4558\n",
      "INFO:tensorflow:step = 6201, loss = 0.2976 (2.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.327\n",
      "INFO:tensorflow:step = 6301, loss = 0.2976 (2.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6509\n",
      "INFO:tensorflow:step = 6401, loss = 0.2976 (2.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6306\n",
      "INFO:tensorflow:step = 6501, loss = 0.2976 (2.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 6601, loss = 0.2976 (2.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5989\n",
      "INFO:tensorflow:step = 6701, loss = 0.2976 (2.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.512\n",
      "INFO:tensorflow:step = 6801, loss = 0.2976 (2.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.839\n",
      "INFO:tensorflow:step = 6901, loss = 0.2976 (2.714 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2976.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:57:42\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-7000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:57:42\n",
      "INFO:tensorflow:Saving dict for global step 7000: accuracy = 0.8, global_step = 7000, loss = 0.1744\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.80000001, 'global_step': 7000, 'loss': 0.17440003}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:57:43\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-7000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:57:44\n",
      "INFO:tensorflow:Saving dict for global step 7000: accuracy = 0.606, global_step = 7000, loss = 0.27496\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 7000, 'loss': 0.27496043}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 7001, loss = 0.1816\n",
      "INFO:tensorflow:global_step/sec: 36.9914\n",
      "INFO:tensorflow:step = 7101, loss = 0.1716 (2.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9858\n",
      "INFO:tensorflow:step = 7201, loss = 0.1716 (2.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1048\n",
      "INFO:tensorflow:step = 7301, loss = 0.1716 (2.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.657\n",
      "INFO:tensorflow:step = 7401, loss = 0.1716 (2.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9743\n",
      "INFO:tensorflow:step = 7501, loss = 0.1716 (2.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8791\n",
      "INFO:tensorflow:step = 7601, loss = 0.1716 (2.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6546\n",
      "INFO:tensorflow:step = 7701, loss = 0.1716 (3.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8965\n",
      "INFO:tensorflow:step = 7801, loss = 0.1716 (2.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8103\n",
      "INFO:tensorflow:step = 7901, loss = 0.1716 (2.958 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1716.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:58:20\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-8000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:58:20\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.7, global_step = 8000, loss = 0.234\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.69999999, 'global_step': 8000, 'loss': 0.23399998}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:58:21\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-8000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:58:22\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.606, global_step = 8000, loss = 0.29016\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 8000, 'loss': 0.29016015}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 8001, loss = 0.1828\n",
      "INFO:tensorflow:global_step/sec: 37.0352\n",
      "INFO:tensorflow:step = 8101, loss = 0.1824 (2.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2332\n",
      "INFO:tensorflow:step = 8201, loss = 0.1824 (2.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2591\n",
      "INFO:tensorflow:step = 8301, loss = 0.1824 (2.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6598\n",
      "INFO:tensorflow:step = 8401, loss = 0.1824 (2.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4118\n",
      "INFO:tensorflow:step = 8501, loss = 0.1824 (2.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3527\n",
      "INFO:tensorflow:step = 8601, loss = 0.1824 (2.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1356\n",
      "INFO:tensorflow:step = 8701, loss = 0.1824 (2.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9837\n",
      "INFO:tensorflow:step = 8801, loss = 0.1824 (2.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0727\n",
      "INFO:tensorflow:step = 8901, loss = 0.1824 (4.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1824.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:59:00\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-9000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:59:00\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.6, global_step = 9000, loss = 0.2848\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Train accuracy {'accuracy': 0.60000002, 'global_step': 9000, 'loss': 0.28480002}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:59:01\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-9000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:59:02\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.606, global_step = 9000, loss = 0.285519\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 9000, 'loss': 0.28551948}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-9000\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:step = 9001, loss = 0.2224\n",
      "INFO:tensorflow:global_step/sec: 36.0709\n",
      "INFO:tensorflow:step = 9101, loss = 0.2224 (2.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4718\n",
      "INFO:tensorflow:step = 9201, loss = 0.2224 (2.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1828\n",
      "INFO:tensorflow:step = 9301, loss = 0.2224 (2.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2874\n",
      "INFO:tensorflow:step = 9401, loss = 0.2224 (2.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5692\n",
      "INFO:tensorflow:step = 9501, loss = 0.2224 (2.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4677\n",
      "INFO:tensorflow:step = 9601, loss = 0.2224 (2.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1278\n",
      "INFO:tensorflow:step = 9701, loss = 0.2224 (2.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.0403\n",
      "INFO:tensorflow:step = 9801, loss = 0.2224 (2.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5699\n",
      "INFO:tensorflow:step = 9901, loss = 0.2224 (2.662 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2224.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:59:39\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:59:39\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.64, global_step = 10000, loss = 0.372\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy {'accuracy': 0.63999999, 'global_step': 10000, 'loss': 0.37200004}\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:59:40\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:59:41\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.606, global_step = 10000, loss = 0.285519\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Validation accuracy {'accuracy': 0.60600001, 'global_step': 10000, 'loss': 0.28551948}\n",
      "Total number of samples : 10000\n",
      "Training samples : 9000\n",
      "Test samples : 1000\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-28-21:59:41\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/4f/dzjlj30x1bv7zk7rdkyspqmc0000gn/T/tmpnlqony14/model.ckpt-10000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-28-21:59:43\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.606, global_step = 10000, loss = 0.285519\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Test accuracy {'accuracy': 0.60600001, 'global_step': 10000, 'loss': 0.28551948}\n"
     ]
    }
   ],
   "source": [
    "# CNN for learning!\n",
    "\n",
    "# learn the states of a double dot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# application logic will be added here\n",
    "def cnn_model_fn(features,labels,mode):\n",
    "    '''Model function for CNN'''\n",
    "    #input layer\n",
    "    input_layer = tf.cast(tf.reshape(features,[-1,30,30,1]),tf.float32)\n",
    "    \n",
    "    # Concolutional layer1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=4,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling layer1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[5,5],strides=5)\n",
    "\n",
    "    # Dense layer\n",
    "    pool2_flat = tf.contrib.layers.flatten(pool1)\n",
    "    dense0 = tf.layers.dense(inputs=pool2_flat,units=512,activation=tf.nn.relu)\n",
    "    dropout0 = tf.layers.dropout(inputs=dense0,rate=0.5,training=mode == learn.ModeKeys.TRAIN)\n",
    "    \n",
    "    dense1 = tf.layers.dense(inputs=dropout0,units=256,activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(inputs=dense1,rate=0.5,training=mode == learn.ModeKeys.TRAIN)\n",
    "    \n",
    "    dense2 = tf.layers.dense(inputs=dropout1,units=128,activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(inputs=dense2,rate=0.5,training=mode == learn.ModeKeys.TRAIN)\n",
    "\n",
    "    # encode layer\n",
    "    encode = tf.layers.dense(inputs=dropout2,units=8)\n",
    "    \n",
    "    # dense output layer\n",
    "    out_layer = tf.layers.dense(inputs=encode,units=1)\n",
    "\n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "    # Calculate loss( for both TRAIN AND EVAL modes)\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=out_layer)\n",
    "\n",
    "    # Configure the training op (for TRAIN mode)\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=0.1,\n",
    "            optimizer=\"Adam\")\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions= {\n",
    "        \"states\" : tf.rint(out_layer),\n",
    "    }\n",
    "\n",
    "    # Returna  ModelFnOps object\n",
    "    return model_fn_lib.ModelFnOps(mode=mode,predictions=predictions,loss=loss, train_op=train_op)\n",
    "    \n",
    "def get_train_inputs():\n",
    "    n_batch = 50\n",
    "    index = np.random.choice(np.arange(train_data.shape[0]),n_batch,replace=False)\n",
    "    x = tf.constant(train_data[index])\n",
    "    y = tf.constant(train_labels[index])\n",
    "    return x,y\n",
    "\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(test_data)\n",
    "    y = tf.constant(test_labels)\n",
    "    return x,y\n",
    "\n",
    "# get the data\n",
    "data_folder_path = \"/Users/sandesh/data_subimage/\"\n",
    "files = glob.glob(data_folder_path + \"*.npy\")\n",
    "inp = []\n",
    "oup = []\n",
    "for file in files[:10000]:\n",
    "    data_dict = np.load(file).item()\n",
    "    inp += [data_dict['current_map']]\n",
    "    oup += [[data_dict['label']]]\n",
    "\n",
    "inp = np.array(inp)\n",
    "oup = np.array(oup)\n",
    "n_samples = inp.shape[0]\n",
    "train_sample_ratio = 0.9\n",
    "n_train = int(train_sample_ratio * n_samples)\n",
    "\n",
    "print(\"Total number of samples :\",n_samples)\n",
    "print(\"Training samples :\",n_train)\n",
    "print(\"Test samples :\",n_samples - n_train)\n",
    "\n",
    "train_data = inp[:n_train]\n",
    "train_labels = oup[:n_train]\n",
    "\n",
    "test_data = inp[n_train:]\n",
    "test_labels = oup[n_train:]\n",
    "\n",
    "# create the estimator\n",
    "dd_classifier = learn.Estimator(model_fn=cnn_model_fn)\n",
    "\n",
    "# set up logging for predictions\n",
    "tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\" : learn.MetricSpec(metric_fn=tf.metrics.accuracy, prediction_key=\"states\"),\n",
    "}\n",
    "for _ in range(10):\n",
    "    dd_classifier.fit(\n",
    "        input_fn=get_train_inputs,\n",
    "        steps=1000,\n",
    "        monitors=[logging_hook])\n",
    "    \n",
    "    eval_results=dd_classifier.evaluate(input_fn=get_train_inputs,metrics=metrics,steps=1)\n",
    "    print(\"Train accuracy\",eval_results)\n",
    "    eval_results=dd_classifier.evaluate(input_fn=get_test_inputs,metrics=metrics,steps=1)\n",
    "    print(\"Validation accuracy\",eval_results)\n",
    "\n",
    "print(\"Total number of samples :\",n_samples)\n",
    "print(\"Training samples :\",n_train)\n",
    "print(\"Test samples :\",n_samples - n_train)\n",
    "eval_results=dd_classifier.evaluate(input_fn=get_test_inputs,metrics=metrics,steps=1)\n",
    "print(\"Test accuracy\",eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
